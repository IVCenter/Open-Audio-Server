==Project Overview==
Rich, 3D environments need sound to provide the user a feeling of complete immersion. When visualization is provided by a cluster of computers, the sound processing can be handled by a dedicated machine that is in turn connected to the speakers and other audio equipment. The OpenAL Audio Server (OAS) provides this functionality via a network interface on a Linux machine. OAS is based loosely on the aging Windows DirectSound [http://www.calit2.net/~jschulze/projects/audioserver/ AudioServer] project by Marc Schreier, and is backwards compatible.

==Status==
* '''Server Backend'''
-- The backend of the server is functional. Connections can be made, instructions and audio files can be sent, and audio can be played, stopped, moved, etc.<br>
-- All network input and output is handled by a dedicated thread that parses the input into discrete audio instructions and queues it up. <br>
-- A separate thread retrieves these instructions from the queue and performs the desired action (i.e. play sound, move sound position, etc.) <br>
-- File format support is limited only by the OpenAL extensions that are installed on the audio server.<br>
-- Server is persistent and stable between different connections. <br>
-- Server settings (port, cache directory, etc.) are read from an XML configuration file.

* '''Server Frontend'''
-- The frontend of the server uses FLTK and currently consists of a tabbed interface. <br>
-- The frontend also resides in its own thread, allowing the user interface to operate independently from the backend of the server. <br>
-- Errors are displayed in bold, warnings are displayed in italics, and informative messages contain no special formatting. <br>

* '''Client API'''
-- Undergoing testing. <br>

----

==Client-Server Communication Protocol==

===Notes on Message Format===
The general format for each message passed from client to the server is a four letter, uppercase
message identifier, followed by any relevant parameters. Since the protocol is in ASCII plain-text,
even integer and floating point numbers are passed as plaintext.

Parameters to messages can be separated by commas, semicolons, or extra spaces. The server's parser 
is lenient with how parameters are separated. So,
<pre>SSPO 4, 3.5, 6, 2.5</pre>
is the same as
<pre>SSPO 4 3.5 6 2.5</pre>
is the same as
<pre>SSPO    4     3.5, 6, 2.5</pre>
is the same as
<pre>SSPO 4;;;;;  3.5,, ;6; 2.5</pre>
However, it is recommended that you stay true to a convention. The provided client API uses the
following convention, to minimize the number of bytes sent over the network:
<pre>SSPO 4 3.5 6 2.5</pre>

===The Protocol===

{| border="1" bgcolor="#FFFFFF"
|-
! scope="col" width="25%" | Message
! scope="col" width="55%" | Description
! scope="col" width="20%" | Example
|-
| 
GHDL filename 
|
Get a handle for a sound source for the <filename>. If <filename> cannot be found in the server's 
cache directory, or a sound source cannot be created for <filename>, the server will respond with
"-1". Otherwise, the response will be a handle number, with values "0", "1", "2", "3", etc.
|
  GHDL beachsound.wav
|-
| 
WAVE type frequency phase duration
| 
Generate a new sound source based on the specified simple waveform. Similar to GHDL, the server 
will respond with a non-negative integer value in ASCII form on success, which will be the handle
for the generated source. On failure, the server will respond with "-1".

<type> specifies the type of the wave, as follows:
* <type> = 1: sinusoidal wave
* <type> = 2: square wave
* <type> = 3: sawtooth wave 
* <type> = 4: whitenoise
* <type> = 5: impulse

<frequency> specifies the [http://en.wikipedia.org/wiki/Audio_frequency frequency] of the waveform. 

<phase> specifies the phase shift of the waveform, in degrees from -180 to +180

<duration> is the duration of the sound in seconds
|
 WAVE 1 261.3 0.0 3.5

Create a sinusoidal wave, with a frequency corresponding to middle-C, a phase shift of 0 degrees, 
and a duration of 3.5 seconds. 
|-
|
RHDL handle
|
Release the resources allocated for the source corresponding to <handle>
|
 RHDL 1
|-
|
PLAY handle
|
Play the source specified by <handle>. If the source is already playing, this will do nothing.
|
 PLAY 5
|-
|
STOP handle
| 
Stop the source specified by <handle>. The playback position is reset to the beginning.
|
 STOP 5
|-
|
SSPO handle x y z
|
Set the sound's position to <x, y, z>. The position values can be floating point.
|
 SSPO 3 4.5 0 22.337

Set sound 3's position to <4.5, 0, 22.337>.
|-
|
SSVE handle x y z
|
Set the sound's velocity to <x, y, z>. These values are only used for doppler effect calculations.
OpenAL does not use the velocity for updating the sound's position, and OAS conforms to this
specification. See the doppler effect for more information on how it works in OAS and OpenAL.

|}

----
==To-Do==
* Extend the [http://code.google.com/p/osgaudio/ osgAudio nodekit] to add support for the OAS client API
* Add server support for instructions that modify listener position and orientation.
* Add more goodies to the front-end (i.e. visual and tabular representation of sound sources)
* Refactor threading system so that the main thread has more complete possession of other threads

==Future Work==
* Enhance sockets code to add support for multiple connected clients. Asynchronous socket I/O.

==Participants==

Software Developers:

* [http://www.linkedin.com/in/shreec Shree Chowkwale]

Project Advisors:

* [http://www.calit2.net/~jschulze/ Jurgen Schulze]

Misc. Development Assistance:

* Philip Weber
* Andrew Prudhomme


Initial Concept Base:

* [http://www.calit2.net/~jschulze/projects/audioserver/ AudioServer Project by Marc Schreier]


